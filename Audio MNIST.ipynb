{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c20c180",
   "metadata": {
    "id": "3c20c180"
   },
   "source": [
    "# Machine Learning\n",
    "## Programming Assessment 5: Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac26b33",
   "metadata": {
    "id": "bac26b33"
   },
   "source": [
    "### Instructions\n",
    "\n",
    "\n",
    "*   The aim of this assignment is to learn machine learning tools - Keras, Sklearn and PyTorch.\n",
    "*   You must use the Python programming language.\n",
    "*   You can add as many code/markdown cells as required.\n",
    "*   ALL cells must be run (and outputs visible) in order to get credit for your work.\n",
    "*   Please use procedural programming style and comment your code thoroughly.\n",
    "*   There are three parts of this assignment. The import statements for the required libraries is already given.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857325dc",
   "metadata": {
    "id": "857325dc"
   },
   "source": [
    "### Introduction\n",
    "In this assignment, you will be using neural networks to implement a simplified version of a speech recognizer which aims to identify what digit has been spoken in a given audio file.\n",
    "\n",
    "In order to accomplish this, you will be using different toolkits, popularly used in machine learning for training models. In this assignment, you will be introduced to Sklearn, Keras, and Pytorch. An implementation from scratch is not required for the purposes of this assignment.\n",
    "\n",
    "Have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6461902f",
   "metadata": {
    "id": "6461902f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ad1548",
   "metadata": {
    "id": "47ad1548"
   },
   "source": [
    "## Part 1: Feature Extraction\n",
    "You will the MNIST audio dataset which can be downloaded from [here](https://www.kaggle.com/datasets/sripaadsrinivasan/audio-mnist). The dataset contains audio recordings, where speakers say digits (0 to 9) out loud. Use the following line of code to read the audio file:\n",
    "```python\n",
    "audio, sr = librosa.load(file_path, sr=16000)\n",
    "```\n",
    "You need to extract MFCC features for each audio file, the feature extraction code is give (you can read about MFCC from [here](https://link.springer.com/content/pdf/bbm:978-3-319-49220-9/1.pdf)). Length of each feature vector will be 13. You need to save all the feature vectors in a csv file with ith column representing ith feature, and each row representing an audio file. Add a 'y' column to the csv file and append the labels column at the end. Your csv file should look like this:\n",
    "\n",
    "| x1 | x2 | x3 | x4 | x5 | x6 | x7 | x8 | x9 | x10 | x11 | x12 | x13 | y |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| -11.347038 | -8.070062 | -0.915299 | 6.859546 | 8.754656 | -3.440287 | -5.738487 | -21.853178 | -9.859462 | 3.584948 | -2.661195\t| 1.023747 | -4.574332 | 2 |\n",
    "\n",
    "Print out 2 vectors in this notebook.\n",
    "\n",
    "Split the dataset into train and test with 80:20 ratio. Print the train data size and test data size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "877edb4d",
   "metadata": {
    "id": "877edb4d"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import python_speech_features as mfcc\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fef48f7",
   "metadata": {
    "id": "0fef48f7"
   },
   "outputs": [],
   "source": [
    "def get_MFCC(audio, sr):\n",
    "    features = mfcc.mfcc(audio, sr, 0.025, 0.01, 13, appendEnergy = True)\n",
    "    return np.mean(features, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b141033",
   "metadata": {
    "id": "3b141033"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Audio\n",
    "file_path = 'data/01/0_01_0.wav'\n",
    "audio, sr = librosa.load(file_path, sr=16000)\n",
    "Audio(audio, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7183177d-8096-4ce8-8600-c140c238ef41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "data_dir = 'data/'\n",
    "file_paths = glob(os.path.join(data_dir,\"*/*.wav\"))\n",
    "data = []\n",
    "labels = []\n",
    "print(len(file_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25ca8174-febe-4554-9f72-89af7c2767c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30000/30000 [09:02<00:00, 55.30it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for file_path in tqdm(file_paths):\n",
    "    label = int(os.path.basename(file_path).split('_')[0])\n",
    "    audio,sr = librosa.load(file_path, sr=16000)\n",
    "    features = get_MFCC(audio, sr)\n",
    "    data.append(features)\n",
    "    labels.append(label)\n",
    "\n",
    "labels = np.array(labels)\n",
    "df = pd.DataFrame(data, columns=[f\"x{i+1}\" for i in range(13)])\n",
    "df['y'] = labels\n",
    "df.to_csv(\"mnist_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf09d8fa-c4e7-4edf-bb71-30ea9fd78716",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mnist_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b125cc19-c277-47cb-a568-933df7c9226f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10.666645</td>\n",
       "      <td>-1.411540</td>\n",
       "      <td>-2.473520</td>\n",
       "      <td>7.168286</td>\n",
       "      <td>-3.494081</td>\n",
       "      <td>-2.785832</td>\n",
       "      <td>-14.398475</td>\n",
       "      <td>-4.217254</td>\n",
       "      <td>3.395590</td>\n",
       "      <td>-11.173119</td>\n",
       "      <td>-2.370115</td>\n",
       "      <td>3.899111</td>\n",
       "      <td>-11.044119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-11.414706</td>\n",
       "      <td>-2.149634</td>\n",
       "      <td>-0.706419</td>\n",
       "      <td>10.050852</td>\n",
       "      <td>1.945194</td>\n",
       "      <td>-5.537895</td>\n",
       "      <td>-12.362039</td>\n",
       "      <td>0.239243</td>\n",
       "      <td>1.692732</td>\n",
       "      <td>-6.133325</td>\n",
       "      <td>3.241282</td>\n",
       "      <td>5.820779</td>\n",
       "      <td>-7.441492</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-10.242019</td>\n",
       "      <td>-2.336824</td>\n",
       "      <td>-5.271823</td>\n",
       "      <td>5.837609</td>\n",
       "      <td>-1.337890</td>\n",
       "      <td>-2.493693</td>\n",
       "      <td>-13.572080</td>\n",
       "      <td>-7.714594</td>\n",
       "      <td>0.306567</td>\n",
       "      <td>-6.591890</td>\n",
       "      <td>-1.882395</td>\n",
       "      <td>3.712337</td>\n",
       "      <td>-6.204464</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-10.193638</td>\n",
       "      <td>-3.643128</td>\n",
       "      <td>-8.129836</td>\n",
       "      <td>2.650802</td>\n",
       "      <td>-0.697407</td>\n",
       "      <td>-8.648287</td>\n",
       "      <td>-18.195700</td>\n",
       "      <td>-2.643146</td>\n",
       "      <td>9.175978</td>\n",
       "      <td>-4.324699</td>\n",
       "      <td>-1.795747</td>\n",
       "      <td>7.319704</td>\n",
       "      <td>-11.465352</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-10.485194</td>\n",
       "      <td>-4.505045</td>\n",
       "      <td>-0.209834</td>\n",
       "      <td>2.821504</td>\n",
       "      <td>-3.985702</td>\n",
       "      <td>-4.391896</td>\n",
       "      <td>-15.959238</td>\n",
       "      <td>-1.718976</td>\n",
       "      <td>2.344726</td>\n",
       "      <td>-8.538168</td>\n",
       "      <td>-1.725910</td>\n",
       "      <td>4.176098</td>\n",
       "      <td>-7.359689</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x1        x2        x3         x4        x5        x6         x7  \\\n",
       "0 -10.666645 -1.411540 -2.473520   7.168286 -3.494081 -2.785832 -14.398475   \n",
       "1 -11.414706 -2.149634 -0.706419  10.050852  1.945194 -5.537895 -12.362039   \n",
       "2 -10.242019 -2.336824 -5.271823   5.837609 -1.337890 -2.493693 -13.572080   \n",
       "3 -10.193638 -3.643128 -8.129836   2.650802 -0.697407 -8.648287 -18.195700   \n",
       "4 -10.485194 -4.505045 -0.209834   2.821504 -3.985702 -4.391896 -15.959238   \n",
       "\n",
       "         x8        x9        x10       x11       x12        x13  y  \n",
       "0 -4.217254  3.395590 -11.173119 -2.370115  3.899111 -11.044119  0  \n",
       "1  0.239243  1.692732  -6.133325  3.241282  5.820779  -7.441492  0  \n",
       "2 -7.714594  0.306567  -6.591890 -1.882395  3.712337  -6.204464  0  \n",
       "3 -2.643146  9.175978  -4.324699 -1.795747  7.319704 -11.465352  0  \n",
       "4 -1.718976  2.344726  -8.538168 -1.725910  4.176098  -7.359689  0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f619530b-488e-481c-a4c7-ca9372ac4fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c02fd9e-f861-46af-b378-06084d8bd325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size (24000, 14)\n",
      "Test Size (6000, 14)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, shuffle=True, random_state=42)\n",
    "print(\"Train Size\", train_df.shape)\n",
    "print(\"Test Size\", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124f0ccd",
   "metadata": {
    "id": "124f0ccd"
   },
   "source": [
    "## Part 2: Neural Network Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1734848",
   "metadata": {
    "id": "b1734848"
   },
   "source": [
    "### Task 2.1:  Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95541b60",
   "metadata": {
    "id": "95541b60"
   },
   "source": [
    "In this part you will use the [Scikit-learn](https://scikit-learn.org/stable/index.html) to implement the [Neural Network](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) and apply it to the MNIST audio dataset (provided in part 1). Split the training dataset into train and evaluation data with 90:10 ratio. Run evaluation on X_eval while training on X_train. Tune the hyperparameters to get the best possible classification accuracy. You need to report accuracy, recall, precision and F1 score on the test dataset and print the confusion matrix.\n",
    "\n",
    "Expected value for accuracy is 87 or above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aaa7f20d",
   "metadata": {
    "id": "aaa7f20d"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0655c48d-1aab-4bb1-ba55-9df5f0bbb40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisation(X_train, X_test):\n",
    "\n",
    "    X_train = np.array(X_train, dtype=float)\n",
    "    X_test = np.array(X_test, dtype=float)\n",
    "\n",
    "    mean = X_train.mean(axis=0)\n",
    "    std = X_train.std(axis=0)\n",
    "    std[std == 0] = 1  # Avoid division by zero\n",
    "\n",
    "    X_train_norm = (X_train - mean) / std\n",
    "    X_test_norm = (X_test - mean) / std\n",
    "\n",
    "    return X_train_norm, X_test_norm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bba71f0f-9452-4ca3-b858-a01051470eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(columns=['y'], axis=1)\n",
    "y = train_df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e8e09b7",
   "metadata": {
    "id": "3e8e09b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size (21600, 13)\n",
      "Val Size (2400, 13)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.1, shuffle=True, random_state=42)\n",
    "print(\"Train Size\", X_train.shape)\n",
    "print(\"Val Size\", X_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8415f144-f5fd-48fd-bbe0-dcf28f8d8738",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc, X_eval_sc = normalisation(X_train, X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d27a5c0a-169b-4745-bf71-2784397e676b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-Learn MLP:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91       225\n",
      "           1       0.95      0.96      0.95       243\n",
      "           2       0.93      0.92      0.93       243\n",
      "           3       0.92      0.95      0.94       255\n",
      "           4       0.98      0.96      0.97       235\n",
      "           5       0.97      0.99      0.98       255\n",
      "           6       1.00      1.00      1.00       237\n",
      "           7       0.97      0.98      0.98       235\n",
      "           8       0.98      0.97      0.98       243\n",
      "           9       0.97      0.95      0.96       229\n",
      "\n",
      "    accuracy                           0.96      2400\n",
      "   macro avg       0.96      0.96      0.96      2400\n",
      "weighted avg       0.96      0.96      0.96      2400\n",
      "\n",
      "[[205   2   6   5   2   2   0   3   0   0]\n",
      " [  1 233   2   0   1   2   0   0   0   4]\n",
      " [ 12   0 223   8   0   0   0   0   0   0]\n",
      " [  1   0   6 243   0   0   0   1   3   1]\n",
      " [  1   6   0   0 226   2   0   0   0   0]\n",
      " [  1   0   0   0   2 252   0   0   0   0]\n",
      " [  0   0   0   0   0   0 236   0   1   0]\n",
      " [  2   0   1   0   0   0   0 231   0   1]\n",
      " [  0   0   1   6   0   0   0   0 236   0]\n",
      " [  1   5   0   1   0   2   0   3   0 217]]\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(256,128,64,32), max_iter=200, learning_rate='adaptive', early_stopping=True, n_iter_no_change=5, random_state=42)\n",
    "mlp.fit(X_train_sc, y_train)\n",
    "y_eval_pred = mlp.predict(X_eval_sc)\n",
    "print(\"Scikit-Learn MLP:\")\n",
    "print(classification_report(y_eval, y_eval_pred))\n",
    "print(confusion_matrix(y_eval, y_eval_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "35ac9b9f-4226-4e6f-b2ce-f0d97994e269",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop(columns=['y'], axis=1)\n",
    "y_test = test_df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "05924932-f38f-4ea2-b8ff-326344c5b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,X_test_sc = normalisation(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "05a0622d-7564-4784-b0e3-349d1a2c549e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-Learn MLP for Testing Data:\n",
      "Accuracy: 0.9521666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93       596\n",
      "           1       0.93      0.97      0.95       599\n",
      "           2       0.93      0.93      0.93       605\n",
      "           3       0.95      0.95      0.95       589\n",
      "           4       0.98      0.96      0.97       607\n",
      "           5       0.97      0.99      0.98       603\n",
      "           6       1.00      0.99      0.99       620\n",
      "           7       0.98      0.97      0.98       589\n",
      "           8       0.97      0.96      0.96       583\n",
      "           9       0.97      0.94      0.96       609\n",
      "\n",
      "    accuracy                           0.96      6000\n",
      "   macro avg       0.96      0.96      0.96      6000\n",
      "weighted avg       0.96      0.96      0.96      6000\n",
      "\n",
      "[[552   6  26   2   3   1   0   4   0   2]\n",
      " [  1 582   2   0   4   1   0   0   0   9]\n",
      " [ 24   4 560  12   0   0   0   2   2   1]\n",
      " [  4   0  14 558   0   0   0   0  12   1]\n",
      " [  4  16   0   0 583   3   0   0   0   1]\n",
      " [  0   1   0   0   3 596   0   1   0   2]\n",
      " [  0   0   0   0   0   3 612   0   5   0]\n",
      " [  6   0   1   0   2   3   0 573   1   3]\n",
      " [  0   0   0  16   0   2   2   2 561   0]\n",
      " [  6  19   0   0   0   6   0   3   0 575]]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = mlp.predict(X_test_sc)\n",
    "print(\"Scikit-Learn MLP for Testing Data:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136613c2",
   "metadata": {
    "id": "136613c2"
   },
   "source": [
    "### Task 2.2: Tensorflow Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aae69f7",
   "metadata": {
    "id": "4aae69f7"
   },
   "source": [
    "In this part you will use the [Keras](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) to implement the [Neural Network](https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/) and apply it to the MNIST audio dataset (provided in part 1). Split the training dataset into train and evaluation data with 90:10 ratio. Run evaluation on X_eval while training on X_train. Tune the hyperparameters to get the best possible classification accuracy. You need to report accuracy, recall, precision and F1 score on the test dataset and print the confusion matrix.\n",
    "\n",
    "Expected value for accuracy is 87 or above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "278f1210",
   "metadata": {
    "id": "278f1210"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6467b611",
   "metadata": {
    "id": "6467b611"
   },
   "outputs": [],
   "source": [
    "# Set the parameters accordingly\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bce54023",
   "metadata": {
    "id": "bce54023"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "675/675 [==============================] - 2s 2ms/step - loss: 0.5975 - accuracy: 0.7932 - val_loss: 0.3588 - val_accuracy: 0.8658\n",
      "Epoch 2/30\n",
      "675/675 [==============================] - 1s 2ms/step - loss: 0.3216 - accuracy: 0.8784 - val_loss: 0.2859 - val_accuracy: 0.8946\n",
      "Epoch 3/30\n",
      "675/675 [==============================] - 1s 2ms/step - loss: 0.2676 - accuracy: 0.9016 - val_loss: 0.2556 - val_accuracy: 0.9062\n",
      "Epoch 4/30\n",
      "675/675 [==============================] - 1s 2ms/step - loss: 0.2403 - accuracy: 0.9103 - val_loss: 0.2370 - val_accuracy: 0.9150\n",
      "Epoch 5/30\n",
      "675/675 [==============================] - 1s 2ms/step - loss: 0.2189 - accuracy: 0.9195 - val_loss: 0.2210 - val_accuracy: 0.9204\n",
      "Epoch 6/30\n",
      "675/675 [==============================] - 2s 2ms/step - loss: 0.2014 - accuracy: 0.9263 - val_loss: 0.2186 - val_accuracy: 0.9225\n",
      "Epoch 7/30\n",
      "675/675 [==============================] - 1s 2ms/step - loss: 0.1870 - accuracy: 0.9325 - val_loss: 0.2022 - val_accuracy: 0.9271\n",
      "Epoch 8/30\n",
      "675/675 [==============================] - 1s 2ms/step - loss: 0.1737 - accuracy: 0.9363 - val_loss: 0.1861 - val_accuracy: 0.9287\n",
      "Epoch 9/30\n",
      "675/675 [==============================] - 1s 2ms/step - loss: 0.1637 - accuracy: 0.9419 - val_loss: 0.1850 - val_accuracy: 0.9358\n",
      "Epoch 10/30\n",
      "675/675 [==============================] - 1s 2ms/step - loss: 0.1516 - accuracy: 0.9445 - val_loss: 0.1709 - val_accuracy: 0.9421\n",
      "Epoch 11/30\n",
      "675/675 [==============================] - 1s 2ms/step - loss: 0.1454 - accuracy: 0.9467 - val_loss: 0.1691 - val_accuracy: 0.9442\n",
      "Epoch 12/30\n",
      "675/675 [==============================] - 1s 2ms/step - loss: 0.1351 - accuracy: 0.9515 - val_loss: 0.1693 - val_accuracy: 0.9446\n",
      "Epoch 13/30\n",
      "675/675 [==============================] - 2s 2ms/step - loss: 0.1275 - accuracy: 0.9535 - val_loss: 0.1646 - val_accuracy: 0.9463\n",
      "Epoch 14/30\n",
      "675/675 [==============================] - 1s 2ms/step - loss: 0.1202 - accuracy: 0.9575 - val_loss: 0.1664 - val_accuracy: 0.9400\n",
      "Epoch 15/30\n",
      "675/675 [==============================] - 1s 2ms/step - loss: 0.1110 - accuracy: 0.9601 - val_loss: 0.1645 - val_accuracy: 0.9488\n",
      "Epoch 16/30\n",
      "675/675 [==============================] - 1s 2ms/step - loss: 0.1081 - accuracy: 0.9613 - val_loss: 0.1678 - val_accuracy: 0.9483\n",
      "Epoch 17/30\n",
      "675/675 [==============================] - 1s 2ms/step - loss: 0.1012 - accuracy: 0.9630 - val_loss: 0.1546 - val_accuracy: 0.9508\n",
      "Epoch 18/30\n",
      "675/675 [==============================] - 1s 2ms/step - loss: 0.0962 - accuracy: 0.9659 - val_loss: 0.1530 - val_accuracy: 0.9521\n",
      "Epoch 19/30\n",
      "675/675 [==============================] - 1s 2ms/step - loss: 0.0899 - accuracy: 0.9676 - val_loss: 0.1604 - val_accuracy: 0.9500\n",
      "Epoch 20/30\n",
      "675/675 [==============================] - 1s 2ms/step - loss: 0.0864 - accuracy: 0.9680 - val_loss: 0.1556 - val_accuracy: 0.9513\n",
      "Epoch 21/30\n",
      "675/675 [==============================] - 2s 3ms/step - loss: 0.0840 - accuracy: 0.9696 - val_loss: 0.1447 - val_accuracy: 0.9533\n",
      "Epoch 22/30\n",
      "675/675 [==============================] - 1s 2ms/step - loss: 0.0772 - accuracy: 0.9719 - val_loss: 0.1675 - val_accuracy: 0.9513\n",
      "Epoch 23/30\n",
      "675/675 [==============================] - 2s 2ms/step - loss: 0.0748 - accuracy: 0.9723 - val_loss: 0.1541 - val_accuracy: 0.9525\n",
      "Epoch 24/30\n",
      "675/675 [==============================] - 2s 2ms/step - loss: 0.0681 - accuracy: 0.9757 - val_loss: 0.1652 - val_accuracy: 0.9488\n",
      "Epoch 25/30\n",
      "675/675 [==============================] - 2s 3ms/step - loss: 0.0700 - accuracy: 0.9750 - val_loss: 0.1558 - val_accuracy: 0.9542\n",
      "Epoch 26/30\n",
      "675/675 [==============================] - 2s 2ms/step - loss: 0.0625 - accuracy: 0.9771 - val_loss: 0.1555 - val_accuracy: 0.9521\n",
      "Epoch 27/30\n",
      "675/675 [==============================] - 1s 2ms/step - loss: 0.0604 - accuracy: 0.9785 - val_loss: 0.1606 - val_accuracy: 0.9550\n",
      "Epoch 28/30\n",
      "675/675 [==============================] - 1s 2ms/step - loss: 0.0583 - accuracy: 0.9796 - val_loss: 0.1497 - val_accuracy: 0.9542\n",
      "Epoch 29/30\n",
      "675/675 [==============================] - 1s 2ms/step - loss: 0.0558 - accuracy: 0.9790 - val_loss: 0.1530 - val_accuracy: 0.9550\n",
      "Epoch 30/30\n",
      "675/675 [==============================] - 1s 2ms/step - loss: 0.0513 - accuracy: 0.9814 - val_loss: 0.1608 - val_accuracy: 0.9517\n",
      "188/188 [==============================] - 0s 1ms/step\n",
      "TensorFlow Keras MLP:\n",
      "Accuracy: 0.9543333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91       596\n",
      "           1       0.94      0.95      0.95       599\n",
      "           2       0.91      0.92      0.92       605\n",
      "           3       0.95      0.93      0.94       589\n",
      "           4       0.99      0.96      0.97       607\n",
      "           5       0.97      0.99      0.98       603\n",
      "           6       1.00      0.99      0.99       620\n",
      "           7       0.97      0.98      0.98       589\n",
      "           8       0.94      0.97      0.96       583\n",
      "           9       0.95      0.94      0.95       609\n",
      "\n",
      "    accuracy                           0.95      6000\n",
      "   macro avg       0.95      0.95      0.95      6000\n",
      "weighted avg       0.95      0.95      0.95      6000\n",
      "\n",
      "[[543   4  34   4   2   0   1   4   1   3]\n",
      " [  3 568   5   0   2   0   0   0   0  21]\n",
      " [ 31   1 557  11   0   0   0   4   1   0]\n",
      " [  4   0  12 548   0   0   1   0  23   1]\n",
      " [  4  14   0   0 583   6   0   0   0   0]\n",
      " [  0   0   0   0   3 599   0   1   0   0]\n",
      " [  0   0   0   1   0   1 612   1   5   0]\n",
      " [  3   0   0   0   0   2   0 578   2   4]\n",
      " [  0   0   0  13   0   2   1   2 565   0]\n",
      " [  3  16   1   2   0   8   0   5   1 573]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(13,)),\n",
    "    Dense(128, activation='silu'),\n",
    "    Dense(64, activation='silu'),\n",
    "    Dense(32, activation='silu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=LEARNING_RATE), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_sc, y_train, validation_data=(X_eval_sc, y_eval), epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "y_pred = np.argmax(model.predict(X_test_sc), axis=1)\n",
    "print(f\"TensorFlow Keras MLP:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611f8a4d",
   "metadata": {
    "id": "611f8a4d"
   },
   "source": [
    "### Task 2.3: Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457d441f",
   "metadata": {
    "id": "457d441f"
   },
   "source": [
    "In this part you will use the [Keras](https://pytorch.org/docs/stable/nn.html) to implement the [Neural Network](https://medium.com/analytics-vidhya/a-simple-neural-network-classifier-using-pytorch-from-scratch-7ebb477422d2) and apply it to the MNIST audio dataset (provided in part 1). Split the training dataset into train and evaluation data with 90:10 ratio. Run evaluation on X_eval while training on X_train. You need to use DataLoader to generate batches of data. Tune the hyperparameters to get the best possible classification accuracy. You need to report training loss, training accuracy, validation loss and validation accuracy after each epoch in the following format:\n",
    "```\n",
    "Epoch 1/2\n",
    "loss: 78.67749792151153 - accuracy: 0.6759259259259259 - val_loss: 6.320814955048263 - val_accuracy: 0.7356481481481482\n",
    "Epoch 2/2\n",
    "loss: 48.70551285566762 - accuracy: 0.7901234567901234 - val_loss: 6.073690168559551 - val_accuracy: 0.7791666666666667\n",
    "```\n",
    "You need to report accuracy, recall, precision and F1 score on the test dataset and print the confusion matrix.\n",
    "\n",
    "Expected value for accuracy is 87 or above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "604e1923",
   "metadata": {
    "id": "604e1923"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdad8b6b",
   "metadata": {
    "id": "bdad8b6b"
   },
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, X_train, y_train):\n",
    "        # Code here\n",
    "        self.X = torch.tensor(X_train, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y_train.values, dtype=torch.long)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Code here\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # Code here\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae160bf9",
   "metadata": {
    "id": "ae160bf9"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden1_size, hidden2_size, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        # Code here\n",
    "        self.fc1 = nn.Linear(input_size, hidden1_size)\n",
    "        self.fc2 = nn.Linear(hidden1_size, hidden2_size)\n",
    "        self.fc3 = nn.Linear(hidden2_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Code here\n",
    "        x = torch.functional.F.silu(self.fc1(x))\n",
    "        x = torch.functional.F.silu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c347a6c9",
   "metadata": {
    "id": "c347a6c9"
   },
   "outputs": [],
   "source": [
    "# Set the parameters accordingly\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "576cacdf",
   "metadata": {
    "id": "576cacdf"
   },
   "outputs": [],
   "source": [
    "# Set the loss function and optimizer accordingly\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# Initialize the model\n",
    "model = NeuralNetwork(input_size=13, hidden1_size=128, hidden2_size=64, output_size=10)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "051ec6b5-18a6-4be8-a0f6-1fbafcbe4bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "129965cc",
   "metadata": {
    "id": "129965cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "loss: 411.84001663 - accuracy: 0.7943981481481481 - val_loss: 26.81809171 - val_accuracy: 0.8708333333333333\n",
      "Epoch 2/30\n",
      "loss: 222.01539905 - accuracy: 0.8752314814814814 - val_loss: 22.09319066 - val_accuracy: 0.8895833333333333\n",
      "Epoch 3/30\n",
      "loss: 190.18859660 - accuracy: 0.8937500000000000 - val_loss: 20.16711137 - val_accuracy: 0.8991666666666667\n",
      "Epoch 4/30\n",
      "loss: 170.62432621 - accuracy: 0.9057407407407407 - val_loss: 17.89054187 - val_accuracy: 0.9083333333333333\n",
      "Epoch 5/30\n",
      "loss: 156.77507711 - accuracy: 0.9137500000000000 - val_loss: 16.90262080 - val_accuracy: 0.9150000000000000\n",
      "Epoch 6/30\n",
      "loss: 145.75258925 - accuracy: 0.9215277777777777 - val_loss: 17.19172376 - val_accuracy: 0.9154166666666667\n",
      "Epoch 7/30\n",
      "loss: 135.99204376 - accuracy: 0.9256481481481481 - val_loss: 15.11402527 - val_accuracy: 0.9279166666666666\n",
      "Epoch 8/30\n",
      "loss: 128.56776706 - accuracy: 0.9295833333333333 - val_loss: 14.67488606 - val_accuracy: 0.9295833333333333\n",
      "Epoch 9/30\n",
      "loss: 120.40518783 - accuracy: 0.9345370370370371 - val_loss: 13.96021782 - val_accuracy: 0.9358333333333333\n",
      "Epoch 10/30\n",
      "loss: 114.98825579 - accuracy: 0.9371296296296296 - val_loss: 14.68912935 - val_accuracy: 0.9291666666666667\n",
      "Epoch 11/30\n",
      "loss: 107.41393417 - accuracy: 0.9433333333333334 - val_loss: 13.55347649 - val_accuracy: 0.9366666666666666\n",
      "Epoch 12/30\n",
      "loss: 102.90345712 - accuracy: 0.9452314814814815 - val_loss: 12.69391887 - val_accuracy: 0.9391666666666667\n",
      "Epoch 13/30\n",
      "loss: 96.85609548 - accuracy: 0.9487037037037037 - val_loss: 13.05948486 - val_accuracy: 0.9395833333333333\n",
      "Epoch 14/30\n",
      "loss: 91.58724807 - accuracy: 0.9526851851851852 - val_loss: 13.20523616 - val_accuracy: 0.9375000000000000\n",
      "Epoch 15/30\n",
      "loss: 89.10145946 - accuracy: 0.9526388888888889 - val_loss: 12.02520857 - val_accuracy: 0.9470833333333334\n",
      "Epoch 16/30\n",
      "loss: 84.26030022 - accuracy: 0.9545833333333333 - val_loss: 11.54313990 - val_accuracy: 0.9470833333333334\n",
      "Epoch 17/30\n",
      "loss: 80.59845648 - accuracy: 0.9581944444444445 - val_loss: 12.14587257 - val_accuracy: 0.9433333333333334\n",
      "Epoch 18/30\n",
      "loss: 77.18737102 - accuracy: 0.9590277777777778 - val_loss: 11.89674982 - val_accuracy: 0.9450000000000000\n",
      "Epoch 19/30\n",
      "loss: 72.81822352 - accuracy: 0.9615740740740740 - val_loss: 11.52046513 - val_accuracy: 0.9466666666666667\n",
      "Epoch 20/30\n",
      "loss: 69.60747090 - accuracy: 0.9646296296296296 - val_loss: 12.02569621 - val_accuracy: 0.9483333333333334\n",
      "Epoch 21/30\n",
      "loss: 68.16643965 - accuracy: 0.9631018518518518 - val_loss: 11.52478604 - val_accuracy: 0.9525000000000000\n",
      "Epoch 22/30\n",
      "loss: 64.93420787 - accuracy: 0.9662500000000001 - val_loss: 12.20422961 - val_accuracy: 0.9433333333333334\n",
      "Epoch 23/30\n",
      "loss: 62.14863376 - accuracy: 0.9667592592592592 - val_loss: 11.19670886 - val_accuracy: 0.9529166666666666\n",
      "Epoch 24/30\n",
      "loss: 59.81388298 - accuracy: 0.9695833333333334 - val_loss: 10.78152587 - val_accuracy: 0.9558333333333333\n",
      "Epoch 25/30\n",
      "loss: 56.52020010 - accuracy: 0.9702314814814815 - val_loss: 10.98541036 - val_accuracy: 0.9512500000000000\n",
      "Epoch 26/30\n",
      "loss: 53.32199494 - accuracy: 0.9732407407407407 - val_loss: 11.61472334 - val_accuracy: 0.9504166666666667\n",
      "Epoch 27/30\n",
      "loss: 51.65144906 - accuracy: 0.9735185185185186 - val_loss: 10.62601510 - val_accuracy: 0.9508333333333333\n",
      "Epoch 28/30\n",
      "loss: 48.92718240 - accuracy: 0.9746296296296296 - val_loss: 10.60035087 - val_accuracy: 0.9545833333333333\n",
      "Epoch 29/30\n",
      "loss: 45.79929730 - accuracy: 0.9760648148148148 - val_loss: 11.11804013 - val_accuracy: 0.9525000000000000\n",
      "Epoch 30/30\n",
      "loss: 45.90073328 - accuracy: 0.9753240740740741 - val_loss: 11.42616756 - val_accuracy: 0.9500000000000000\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(Data(X_train_sc, y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
    "eval_loader = DataLoader(Data(X_eval_sc, y_eval), batch_size=BATCH_SIZE, shuffle=False)\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = loss_function(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        train_correct += (preds == y_batch).sum().item()\n",
    "\n",
    "    train_accuracy = train_correct / len(X_train)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in eval_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            outputs = model(X_batch)\n",
    "            loss = loss_function(outputs, y_batch)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            val_correct += (preds == y_batch).sum().item()\n",
    "\n",
    "    val_accuracy = val_correct / len(X_eval)\n",
    "    \n",
    "    print(f\"Epoch {epoch}/{EPOCHS}\")\n",
    "    print(f\"loss: {train_loss:.8f} - accuracy: {train_accuracy:.16f} \" f\"- val_loss: {val_loss:.8f} - val_accuracy: {val_accuracy:.16f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "22946d24-8e84-44a3-b33f-c4d4e1147ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation:\n",
      "Accuracy : 0.9540\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92       596\n",
      "           1       0.94      0.95      0.95       599\n",
      "           2       0.96      0.85      0.90       605\n",
      "           3       0.93      0.96      0.95       589\n",
      "           4       0.98      0.98      0.98       607\n",
      "           5       0.98      0.99      0.98       603\n",
      "           6       0.99      0.99      0.99       620\n",
      "           7       0.97      0.97      0.97       589\n",
      "           8       0.96      0.97      0.97       583\n",
      "           9       0.95      0.94      0.94       609\n",
      "\n",
      "    accuracy                           0.95      6000\n",
      "   macro avg       0.95      0.95      0.95      6000\n",
      "weighted avg       0.95      0.95      0.95      6000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[563   2  15   4   4   0   1   3   0   4]\n",
      " [  4 568   3   0   3   1   0   0   0  20]\n",
      " [ 47   4 516  29   0   0   0   6   2   1]\n",
      " [  2   0   1 567   0   0   0   1  17   1]\n",
      " [  5   8   0   0 592   1   0   0   0   1]\n",
      " [  2   0   0   0   2 594   0   1   1   3]\n",
      " [  0   0   0   0   0   3 612   0   5   0]\n",
      " [  6   1   1   0   2   4   1 571   0   3]\n",
      " [  0   0   0   7   0   2   4   2 568   0]\n",
      " [  4  20   1   1   2   3   0   4   1 573]]\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(Data(X_test_sc, y_test), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        outputs = model(X_batch)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "clf_report = classification_report(all_labels, all_preds)\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "print(\"Test Set Evaluation:\")\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Classification Report :\")\n",
    "print(clf_report)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1063054,
     "sourceId": 1788543,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
