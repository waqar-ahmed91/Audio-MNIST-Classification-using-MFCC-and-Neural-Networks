# -*- coding: utf-8 -*-
"""MNIST.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MinU3_yelttJTNEGUhM4XL1V5oBEmawv

# Machine Learning
"""

import numpy as np
import pandas as pd

"""## Part 1: Feature Extraction
You will the MNIST audio dataset which can be downloaded from [here](https://www.kaggle.com/datasets/sripaadsrinivasan/audio-mnist). The dataset contains audio recordings, where speakers say digits (0 to 9) out loud. Use the following line of code to read the audio file:
```python
audio, sr = librosa.load(file_path, sr=16000)
```
You need to extract MFCC features for each audio file, the feature extraction code is give (you can read about MFCC from [here](https://link.springer.com/content/pdf/bbm:978-3-319-49220-9/1.pdf)). Length of each feature vector will be 13. You need to save all the feature vectors in a csv file with ith column representing ith feature, and each row representing an audio file. Add a 'y' column to the csv file and append the labels column at the end. Your csv file should look like this:

| x1 | x2 | x3 | x4 | x5 | x6 | x7 | x8 | x9 | x10 | x11 | x12 | x13 | y |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| -11.347038 | -8.070062 | -0.915299 | 6.859546 | 8.754656 | -3.440287 | -5.738487 | -21.853178 | -9.859462 | 3.584948 | -2.661195	| 1.023747 | -4.574332 | 2 |

Print out 2 vectors in this notebook.

Split the dataset into train and test with 80:20 ratio. Print the train data size and test data size.
"""

from glob import glob
import python_speech_features as mfcc
import librosa
from sklearn.model_selection import train_test_split

def get_MFCC(audio, sr):
    features = mfcc.mfcc(audio, sr, 0.025, 0.01, 13, appendEnergy = True)
    return np.mean(features, axis=0)

from IPython.display import Audio
file_path = 'data/01/0_01_0.wav'
audio, sr = librosa.load(file_path, sr=16000)
Audio(audio, rate=sr)

import os
data_dir = 'data/'
file_paths = glob(os.path.join(data_dir,"*/*.wav"))
data = []
labels = []
print(len(file_paths))

from tqdm import tqdm
for file_path in tqdm(file_paths):
    label = int(os.path.basename(file_path).split('_')[0])
    audio,sr = librosa.load(file_path, sr=16000)
    features = get_MFCC(audio, sr)
    data.append(features)
    labels.append(label)

labels = np.array(labels)
df = pd.DataFrame(data, columns=[f"x{i+1}" for i in range(13)])
df['y'] = labels
df.to_csv("mnist_features.csv", index=False)

df = pd.read_csv("mnist_features.csv")

df.head()

df.y.unique()

train_df, test_df = train_test_split(df, test_size=0.2, shuffle=True, random_state=42)
print("Train Size", train_df.shape)
print("Test Size", test_df.shape)

"""## Part 2: Neural Network Implementation

### Task 2.1:  Scikit-learn

In this part you will use the [Scikit-learn](https://scikit-learn.org/stable/index.html) to implement the [Neural Network](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) and apply it to the MNIST audio dataset (provided in part 1). Split the training dataset into train and evaluation data with 90:10 ratio. Run evaluation on X_eval while training on X_train. Tune the hyperparameters to get the best possible classification accuracy. You need to report accuracy, recall, precision and F1 score on the test dataset and print the confusion matrix.

Expected value for accuracy is 87 or above.
"""

from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

def normalisation(X_train, X_test):

    X_train = np.array(X_train, dtype=float)
    X_test = np.array(X_test, dtype=float)

    mean = X_train.mean(axis=0)
    std = X_train.std(axis=0)
    std[std == 0] = 1  # Avoid division by zero

    X_train_norm = (X_train - mean) / std
    X_test_norm = (X_test - mean) / std

    return X_train_norm, X_test_norm

X = train_df.drop(columns=['y'], axis=1)
y = train_df['y']

X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.1, shuffle=True, random_state=42)
print("Train Size", X_train.shape)
print("Val Size", X_eval.shape)

X_train_sc, X_eval_sc = normalisation(X_train, X_eval)

mlp = MLPClassifier(hidden_layer_sizes=(256,128,64,32), max_iter=200, learning_rate='adaptive', early_stopping=True, n_iter_no_change=5, random_state=42)
mlp.fit(X_train_sc, y_train)
y_eval_pred = mlp.predict(X_eval_sc)
print("Scikit-Learn MLP:")
print(classification_report(y_eval, y_eval_pred))
print(confusion_matrix(y_eval, y_eval_pred))

X_test = test_df.drop(columns=['y'], axis=1)
y_test = test_df['y']

_,X_test_sc = normalisation(X_train, X_test)

y_test_pred = mlp.predict(X_test_sc)
print("Scikit-Learn MLP for Testing Data:")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_test_pred))
print(confusion_matrix(y_test, y_test_pred))

"""### Task 2.2: Tensorflow Keras

In this part you will use the [Keras](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) to implement the [Neural Network](https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/) and apply it to the MNIST audio dataset (provided in part 1). Split the training dataset into train and evaluation data with 90:10 ratio. Run evaluation on X_eval while training on X_train. Tune the hyperparameters to get the best possible classification accuracy. You need to report accuracy, recall, precision and F1 score on the test dataset and print the confusion matrix.

Expected value for accuracy is 87 or above.
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras import optimizers

# Set the parameters accordingly
LEARNING_RATE = 0.001
BATCH_SIZE = 32
EPOCHS = 30

model = Sequential([
    Input(shape=(13,)),
    Dense(128, activation='silu'),
    Dense(64, activation='silu'),
    Dense(32, activation='silu'),
    Dense(10, activation='softmax')
])

model.compile(optimizer=optimizers.Adam(learning_rate=LEARNING_RATE), loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(X_train_sc, y_train, validation_data=(X_eval_sc, y_eval), epochs=EPOCHS, batch_size=BATCH_SIZE)
y_pred = np.argmax(model.predict(X_test_sc), axis=1)
print(f"TensorFlow Keras MLP:")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

"""### Task 2.3: Pytorch

In this part you will use the [Keras](https://pytorch.org/docs/stable/nn.html) to implement the [Neural Network](https://medium.com/analytics-vidhya/a-simple-neural-network-classifier-using-pytorch-from-scratch-7ebb477422d2) and apply it to the MNIST audio dataset (provided in part 1). Split the training dataset into train and evaluation data with 90:10 ratio. Run evaluation on X_eval while training on X_train. You need to use DataLoader to generate batches of data. Tune the hyperparameters to get the best possible classification accuracy. You need to report training loss, training accuracy, validation loss and validation accuracy after each epoch in the following format:
```
Epoch 1/2
loss: 78.67749792151153 - accuracy: 0.6759259259259259 - val_loss: 6.320814955048263 - val_accuracy: 0.7356481481481482
Epoch 2/2
loss: 48.70551285566762 - accuracy: 0.7901234567901234 - val_loss: 6.073690168559551 - val_accuracy: 0.7791666666666667
```
You need to report accuracy, recall, precision and F1 score on the test dataset and print the confusion matrix.

Expected value for accuracy is 87 or above.
"""

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import accuracy_score

class Data(Dataset):
    def __init__(self, X_train, y_train):
        # Code here
        self.X = torch.tensor(X_train, dtype=torch.float32)
        self.y = torch.tensor(y_train.values, dtype=torch.long)

    def __getitem__(self, index):
        # Code here
        return self.X[index], self.y[index]

    def __len__(self):
        # Code here
        return len(self.X)

class NeuralNetwork(nn.Module):
    def __init__(self, input_size, hidden1_size, hidden2_size, output_size):
        super(NeuralNetwork, self).__init__()
        # Code here
        self.fc1 = nn.Linear(input_size, hidden1_size)
        self.fc2 = nn.Linear(hidden1_size, hidden2_size)
        self.fc3 = nn.Linear(hidden2_size, output_size)

    def forward(self, x):
        # Code here
        x = torch.functional.F.silu(self.fc1(x))
        x = torch.functional.F.silu(self.fc2(x))
        x = self.fc3(x)
        return x

# Set the parameters accordingly
LEARNING_RATE = 0.001
BATCH_SIZE = 32
EPOCHS = 30

# Set the loss function and optimizer accordingly
loss_function = nn.CrossEntropyLoss()
# Initialize the model
model = NeuralNetwork(input_size=13, hidden1_size=128, hidden2_size=64, output_size=10)
optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)

train_loader = DataLoader(Data(X_train_sc, y_train), batch_size=BATCH_SIZE, shuffle=True)
eval_loader = DataLoader(Data(X_eval_sc, y_eval), batch_size=BATCH_SIZE, shuffle=False)
model.to(device)

for epoch in range(1, EPOCHS + 1):
    model.train()
    train_loss = 0.0
    train_correct = 0

    for X_batch, y_batch in train_loader:
        X_batch, y_batch = X_batch.to(device), y_batch.to(device)

        optimizer.zero_grad()
        outputs = model(X_batch)
        loss = loss_function(outputs, y_batch)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        preds = torch.argmax(outputs, dim=1)
        train_correct += (preds == y_batch).sum().item()

    train_accuracy = train_correct / len(X_train)

    model.eval()
    val_loss = 0.0
    val_correct = 0

    with torch.no_grad():
        for X_batch, y_batch in eval_loader:
            X_batch, y_batch = X_batch.to(device), y_batch.to(device)

            outputs = model(X_batch)
            loss = loss_function(outputs, y_batch)

            val_loss += loss.item()
            preds = torch.argmax(outputs, dim=1)
            val_correct += (preds == y_batch).sum().item()

    val_accuracy = val_correct / len(X_eval)

    print(f"Epoch {epoch}/{EPOCHS}")
    print(f"loss: {train_loss:.8f} - accuracy: {train_accuracy:.16f} " f"- val_loss: {val_loss:.8f} - val_accuracy: {val_accuracy:.16f}")

test_loader = DataLoader(Data(X_test_sc, y_test), batch_size=BATCH_SIZE, shuffle=False)

model.eval()

all_preds = []
all_labels = []

with torch.no_grad():
    for X_batch, y_batch in test_loader:
        X_batch, y_batch = X_batch.to(device), y_batch.to(device)

        outputs = model(X_batch)
        preds = torch.argmax(outputs, dim=1)

        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(y_batch.cpu().numpy())

accuracy = accuracy_score(all_labels, all_preds)
clf_report = classification_report(all_labels, all_preds)
conf_matrix = confusion_matrix(all_labels, all_preds)

print("Test Set Evaluation:")
print(f"Accuracy : {accuracy:.4f}")
print(f"Classification Report :")
print(clf_report)
print("Confusion Matrix:")
print(conf_matrix)